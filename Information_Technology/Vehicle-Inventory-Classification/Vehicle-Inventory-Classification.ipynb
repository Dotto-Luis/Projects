{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGwrUZSxXSuG"
   },
   "source": [
    "# AnyoneAI - Sprint Project 04\n",
    "> Vehicle Classification\n",
    "\n",
    "You've been learning a lot about Deep Learning Algorithms, now we you're gonna be asked to put it all together. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1680033779007,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "5bcJoaR6YahS",
    "outputId": "8ffde720-b93c-4b78-e804-f820bf2dbd7e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "IN_COLAB = \"google.colab\" in sys.modules\n",
    "IN_COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26895,
     "status": "ok",
     "timestamp": 1680028888362,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "_9ohQ9PnXeZx",
    "outputId": "640e4dd1-946d-491e-a010-113537e668f7"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226,
     "status": "ok",
     "timestamp": 1680033781336,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "MOmDt--lXwUQ",
    "outputId": "107fe30a-da87-4927-b51f-a6532397dce6"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # Put here the full path to the folder having your Sprint project code\n",
    "    # e.g. \"/content/drive/MyDrive/assignment\"\n",
    "    ROOT_DIR = \"/content/drive/MyDrive/Colab_Notebooks/Information_Technology/assignment\"\n",
    "    %cd $ROOT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3twXxeDrr8u"
   },
   "source": [
    "## Install dependencies (Only for Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 89953,
     "status": "ok",
     "timestamp": 1680028980620,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "nxv7tDMorr8y",
    "outputId": "a41ca9a0-8596-4f83-cff1-58ff94a28860"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # This will make sure you have installed all the proper dependencies\n",
    "    # Instal dependencies\n",
    "    !pip install -r requirements.txt\n",
    "    # We can access to GPUs in Colab, so install GPU version of tensorflow\n",
    "    !pip install tensorflow-gpu==2.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_k9xfyOXSuH"
   },
   "source": [
    "## 1. Introduction\n",
    "\n",
    "This is a Multi-class Classification task: we want to predict, given a picture of a vehicle, which of the possible 25 classes is the correct vehicle make-model.\n",
    "\n",
    "The dataset is composed of JPG images, already stored in folders containing the label (vehicle make-model), separated in train and test sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6562,
     "status": "ok",
     "timestamp": 1680033789818,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "nhrF6OAAXSuI"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/content/drive/MyDrive/Colab_Notebooks/Information_Technology/assignment')\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from src import data_utils, models, config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqPF-5jcXSuI"
   },
   "source": [
    "### Getting the data\n",
    "\n",
    "To access the data for this project, you only need to execute the code below. This will download a zip file `cars_25_dataset.zip` containing inside:\n",
    "\n",
    "- `car_ims_dataset`: Folder whit train and test images, already classified in sub-folders with the corresponding vehicle label.\n",
    "\n",
    "- `train_dataset_annos.csv` and `test_dataset_annos.csv`: Train and test images annotations provided in CSV file format. You will not need these files unless you want to solve the optional exercises.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlO06ncGXSuJ"
   },
   "source": [
    "1.1. Download the training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2957,
     "status": "ok",
     "timestamp": 1680033792773,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "DihttAYcXSuJ"
   },
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    config.DATASET_ROOT_PATH = \"/content/drive/MyDrive/Colab_Notebooks/Information_Technology/assignment/dataset/\"\n",
    "\n",
    "data_utils.download_datasets(config.DATASET_ROOT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3nu9NVUbXSuJ"
   },
   "source": [
    "1.2. Setup some variables you will use during training the model.\n",
    "\n",
    "The default values used here should work fine for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1680033792773,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "X8Dc0jEwXSuJ"
   },
   "outputs": [],
   "source": [
    "# Dataset folder\n",
    "DATASET_FOLDER = os.path.join(config.DATASET_ROOT_PATH, config.DATASET_FILENAME)\n",
    "DATASET_FOLDER = os.path.join(config.DATASET_ROOT_PATH, \"eu-car-dataset_subset\")\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTiXjhZxXSuK"
   },
   "source": [
    "1.3. Load the training and testing images as a Tensorflow dataset (`tf.data.Dataset`).\n",
    "\n",
    "Note that it's not a good idea to load all the images into memory because they may need more RAM than the one installed in the system. This is why we create generators using the `image_dataset_from_directory()` function, which loads the images only when they are needed and then releases the memory for loading another batch of new images from the disk.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gM2-j_l3XSuK"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1367,
     "status": "ok",
     "timestamp": 1680033794137,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "D79NvbS3XSuK",
    "outputId": "90b3dee1-ed93-45c2-c0a0-a56a118dd1f1"
   },
   "outputs": [],
   "source": [
    "# Load train and test datasets\n",
    "train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"train\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=os.path.join(DATASET_FOLDER, \"test\"),\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBzwpVV2XSuK"
   },
   "source": [
    "**Checkpoint:** The cell above should output the following message:\n",
    "\n",
    "```code\n",
    "Found 7509 files belonging to 25 classes.\n",
    "Found 1875 files belonging to 25 classes.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5ag5bjyXSuL"
   },
   "source": [
    "## 2. Basic EDA\n",
    "\n",
    "Let's load and display some pictures with their labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiSi6U8CXSuL"
   },
   "source": [
    "2.1. Take the class names automatically inferred from the data generator and assign to `class_names` variable. We will use this to do some EDA and also to define the output units in the classification layer of our model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yIGNf-xhXSuL"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1680033794137,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "xEvAmzyaXSuL",
    "outputId": "21f4372d-ae52-4ae7-f97f-8d98a5afa771"
   },
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)\n",
    "\n",
    "assert len(class_names) == 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njmqutOKXSuL"
   },
   "source": [
    "2.2. Let's show some pictures!\n",
    "\n",
    "You can re-run the following cell as many times as you want and it will always show a new set of images and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTr4OcMdXSuL"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "executionInfo": {
     "elapsed": 3092,
     "status": "ok",
     "timestamp": 1680033797227,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "RDeaiTjPXSuL",
    "outputId": "a25bef1c-e1ac-4578-9fe7-6ae4e5c39ea1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[np.argmax(labels[i])])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f0ncq2VXSuM"
   },
   "source": [
    "**Don't change anything in this cell, just make it run correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1680033797227,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "A7Ka7NzsXSuM"
   },
   "outputs": [],
   "source": [
    "# Configure data loader for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddODkQqKXSuM"
   },
   "source": [
    "## 3. Multi-layer Perceptron\n",
    "\n",
    "*Now it's time to train our first Neural Network model. For simplicity, we are going to try using an MLP model.*\n",
    "\n",
    "*A Multi-layer Perceptron (MLP) is a simple neural network consisting of multiple layers of nodes connected by weighted edges. The input and output layers have one node per feature, and one node per target class respectively, while the intermediate layers have an arbitrary number of nodes. MLPs are known to work well for simple classification tasks, but they might not be suitable for image classification, where the input data has a high dimensionality and there are correlations between adjacent pixels.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_mlp_model()` functions you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_mlp_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 253679,
     "status": "ok",
     "timestamp": 1680034364477,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "Zf2uzXf_XSuM",
    "outputId": "ec3837de-4700-4820-9cf0-8e64c8c4ac03"
   },
   "outputs": [],
   "source": [
    "mlp_model = models.create_mlp_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "mlp_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-6),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "mlp_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNisyJIuXSuM"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.3*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "- Final training accuracy: 0.6533\n",
    "\n",
    "- Final validation accuracy: 0.2997\n",
    "\n",
    "The validation accuracy is significantly lower than the training accuracy, suggesting that the model might be overfitting the training data.\n",
    "With the original value learning_rate=5e-6, I got:\n",
    "\n",
    "Epoch 30/30\n",
    "235/235 [==============================] - 7s 31ms/step - loss: 1.3838 - accuracy: 0.6533 - val_loss: 2.5332 - val_accuracy: 0.2997\n",
    "\n",
    "Then I reduced this value to `1e-6` and it gave me:\n",
    "\n",
    "Epoch 30/30\n",
    "235/235 [==============================] - 7s 31ms/step - loss: 1.9179 - accuracy: 0.5105 - val_loss: 2.5635 - val_accuracy: 0.2693\n",
    "\n",
    "So I decided to increase the value of the learning rate instead of reducing it; I set it to 9e-6, and it gave me:\n",
    "Epoch 30/30\n",
    "235/235 [==============================] - 7s 31ms/step - loss: 1.2339 - accuracy: 0.6852 - val_loss: 2.5922 - val_accuracy: 0.2869\n",
    "\n",
    "Finally, I added a callback1 to optimize for accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjgC2oE3XSuM"
   },
   "source": [
    "## 4. CNN: LeNet\n",
    "\n",
    "*Multi-layer Perceptrons are known to work well for simple classification tasks, but they might not be suitable for image classification, where the input data has a high dimensionality and there are correlations between adjacent pixels.*\n",
    "\n",
    "*If the previous model wasn't enough for the accuracy we aim to achieve, we can try a bigger one, a Convolutional Network! We are going to use the first develop CNN, the LeNet model.*\n",
    "\n",
    "*LeNet is a type of Convolutional Neural Network (CNN) that was specifically designed for image classification. LeNet uses a set of convolutional layers to extract low-level features such as edges and corners, and then combines them into higher-level features through a series of pooling layers. Finally, a set of fully connected layers is used to classify the images. LeNet has shown to be very effective in image classification tasks, especially in cases where the input images are small and the features are not too complex.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_lenet_model()` function you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_lenet_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123222,
     "status": "ok",
     "timestamp": 1680034085825,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "plHTcrRaXSuM",
    "outputId": "4e93fea3-3cb8-4002-825a-1dcb6898e916"
   },
   "outputs": [],
   "source": [
    "lenet_model = models.create_lenet_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "lenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "lenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqu3u4bMXSuN"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.3*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "It is observed that the accuracy on the training set (accuracy) is relatively high (approximately 85.46%), but the accuracy on the validation set (val_accuracy) is lower (approximately 31.73%). This pattern suggests that the model might be experiencing some degree of overfitting, as the accuracy on the training set is significantly higher than the accuracy on the validation set.\n",
    "\n",
    "There have been 13 attempts to fine-tune the current model, but achieving an 80% accuracy has not been successful. This LeNet model is quite simplistic and may lack the complexity needed to capture more intricate patterns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcallbacks\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopping\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m lenet_model \u001b[39m=\u001b[39m models\u001b[39m.\u001b[39mcreate_lenet_model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     input_shape\u001b[39m=\u001b[39m(img_height, img_width, \u001b[39m3\u001b[39m), num_classes\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(class_names)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Compile the model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "lenet_model = models.create_lenet_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "lenet_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=4e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Agrega EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "lenet_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=15,  # Aumenta el número de épocas\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ABgyuCLXSuN"
   },
   "source": [
    "## 5. CNN: Transfer learning from ResNet50\n",
    "\n",
    "*Maybe the LeNet is still no the best choice for our task. Actually, most of the time, when solving image classification problems, the best results are achieved using pre-built CNN architecture pre-trained on imagenet dataset. This process is commonly known as **transfer learning** or **fine-tuning**.*\n",
    "\n",
    "*ResNet50, is a much deeper CNN that was developed to tackle the problem of vanishing gradients in deep neural networks. ResNet50 is made up of many layers that are organized into blocks, each of which has a set of convolutional layers followed by shortcut connections that allow for the easy flow of information between layers. These shortcut connections help to prevent vanishing gradients and allow the network to learn very deep representations of the input images. This makes ResNet50 ideal for image classification tasks where the input images are complex and large.*\n",
    "\n",
    "*Therefore, it would be better to use ResNet50 finetuning for image classification tasks, especially if the input images are complex and large, as it has been optimized for this specific task and has shown to be very effective in achieving state-of-the-art results. Additionally, using ResNet50 finetuning means that the model can take advantage of the pre-trained weights on a large dataset, which can lead to faster convergence and better performance on smaller datasets.*\n",
    "\n",
    "---\n",
    "\n",
    "Executing the following cell will create a model using the `create_resnet50_model()` function you created and then run the training pipeline for it.\n",
    "\n",
    "Feel free to change the code below to include any other optimization algorithm or change the default optimizer parameters like the `learning rate`.\n",
    "\n",
    "It's also a good idea to change and experiment with different parameters for the `fit()` function. Try with more epochs and also adding [callbacks](https://keras.io/api/callbacks/) for saving the best weights (`ModelCheckpoint`), storing training logs (`TensorBoard` or `CSVLogger`), changing learning rate during training depending on the improvements in the loss function (`ReduceLROnPlateau`), etc.\n",
    "\n",
    "**Important note:** Don't modify the model layers in the `create_resnet50_model()` with different parameters to what we asked you to do in the function or you will break the project unit tests. If you want to experiment further with other model settings, feel free to create your own model in a separate function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "It is observed that the accuracy on the training set (accuracy) is relatively high (approximately 85.46%), but the accuracy on the validation set (val_accuracy) is lower (approximately 31.73%). This pattern suggests that the model might be experiencing some degree of overfitting, as the accuracy on the training set is significantly higher than the accuracy on the validation set\n",
    "\n",
    "There have been 13 attempts to fine-tune the current model, but achieving an 80% accuracy has not been successful. This Multi-layer Perceptron model is quite simplistic and may lack the complexity needed to capture more intricate patterns in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 258517,
     "status": "ok",
     "timestamp": 1680030996784,
     "user": {
      "displayName": "Pablo Pastore",
      "userId": "13868799798828179067"
     },
     "user_tz": 180
    },
    "id": "Ggl0lBCbXSuN",
    "outputId": "305a112e-1dbf-4f0c-93d7-6f1cfa544493"
   },
   "outputs": [],
   "source": [
    "resnet50_model = models.create_resnet50_model(\n",
    "    input_shape=(img_height, img_width, 3), num_classes=len(class_names)\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "resnet50_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=5e-4),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "resnet50_model.fit(\n",
    "    train_ds,\n",
    "    validation_data=test_ds,\n",
    "    epochs=20,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(\n",
    "            patience=5,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Id2gi6Jxt6t1"
   },
   "source": [
    "At this point the model accuracy in the validation dataset should be around *0.7*.\n",
    "\n",
    "What do you think about the relation between training accuracy and validation accuracy? Is the model overfitting or underfitting?\n",
    "\n",
    "What changes can we apply to reach our goal of 0.8 (80%) accuracy on testing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "The validation accuracy is 74.40%, while the training accuracy is 96.54%, indicating a potential degree of overfitting. In a different context, it is stated that this model is superior to the other two in this particular case. The hyperparameter for the learning rate was adjusted from 4e-5 to 2e-5, successfully achieving the desired 80% accuracy goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIeSxfo2vNiE"
   },
   "source": [
    "## 6. Analyze model results\n",
    "\n",
    "Choose your best model and report some metrics on the results you obtained.\n",
    "\n",
    "You can plot a confussion matrix or use [Scikit-learn classification report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UJXJrLC_vogg"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb Cell 42\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix, classification_report\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/nr600/Documents/Projects/Information_Technology/Vehicle-Inventory-Classification/Vehicle-Inventory-Classification.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Get predictions on the test dataset\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Get predictions on the test dataset\n",
    "predictions = resnet50_model.predict(test_ds)\n",
    "\n",
    "# Create a variable list of class labels\n",
    "class_names = sorted(os.listdir(os.path.join(DATASET_FOLDER, \"train\")))\n",
    "\n",
    "# Convert one-hot encoded predictions to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels from the test dataset\n",
    "true_labels = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Create a confusion matrix\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Order the confusion matrix by the diagonal values\n",
    "sorted_indices = np.argsort(np.diag(cm))[::-1]\n",
    "cm_sorted = cm[:, sorted_indices][sorted_indices, :]\n",
    "\n",
    "# Plot the sorted confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_sorted, annot=True, fmt='d', cmap='Blues', xticklabels=np.array(class_names)[sorted_indices], yticklabels=np.array(class_names)[sorted_indices])\n",
    "plt.title('Sorted Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# Display the classification report\n",
    "print(\"Classification Report:\\n\", classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hY2lgAH-XSuN"
   },
   "source": [
    "## 7. Optional. Make your own model\n",
    "\n",
    "The models we've trained before are just a limited set over the universe of stuff you can use. \n",
    "\n",
    "You still have a lot of things to experiment with to increase accuracy, some ideas are:\n",
    "\n",
    "1. Use any other CNN architecture you think may perform better than ResNet50.\n",
    "2. Try adding data augmentation or any other regularization algorithms.\n",
    "3. Train using more epochs, a different optimization algorithm, etc.\n",
    "4. Check [KerasTuner](https://keras.io/api/keras_tuner/) documentation about how to efficiently test a lot of different architectures and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i4YozyqCvqz6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "S04",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
